\chapter{绪论}
视觉社区已在短时间迅速改进了对象检测和短语期间的语义分割结果。在很大程度上，这些进步已经被强大的基线系统推动，例如Fast / Faster RCNN和完全卷积网络（FCN）分别对应对象检测和语义分割的框架。 这些方法在概念上是直观的，并具有灵活性和稳健性，以及快速培训和推理时间。 我们在这项工作中的目标是开发一个相对可行的实例分割框架。\par
实例细分具有挑战性，因为它需要同时正确检测图像中的所有对象并精确地分割每个实例。 因此它结合了经典计算机视觉任务的目标检测和语义分段，前者的目标是使用边界框对单个对象进行分类和定位，后者的目标是将每个像素分类为一组固定的类别，不区分对象实例。鉴于此，人们可能会期待一种复杂的方法要取得好成绩。 但是，我们提出了一个可以超越先前的最新实例分割结果的简单，灵活，快速令人惊讶的系统。\par

我们的方法称为Mask R-CNN，它扩展了Faster R-CNN通过添加一个与现有用于分类和边界框回归的分支区域平行的分支来在每个感兴趣区域（RoI）预测分割掩码。（图1）。 掩码分支是应用于每个RoI的小FCN，用于预测像素到像素中的分割掩模方式。 在Faster R-CNN框架下Mask R-CNN易于实现和训练，这促进了广泛的灵活架构设计。 另外，掩码分支只增加了一个小的计算开销，实现快速系统和快速实验。\par
原则上，Mask R-CNN直观上是一个Faster R-CNN的扩展，但正确构建掩模分支对于取得好成绩至关重要。最重要的是，Faster R-CNN不是为网络输入和输出间像素到像素之间的对齐而设计的。这一点在RoIPool（解决事例核心操作的关键）如何执行用于特征提取的粗略空间量化中最为明显。为了解决这个错位，我们提出一个简单的，无量化的层，称为RoIAlign，它忠实地保留确切的空间位置。尽管看似微不足道的变化，但RoIAlign产生了巨大的影响：掩模精度​​提高了10％到50％，显示出更严格的本地化指标带来更大的收益。第二，我们发现解耦掩模和类别预测很重要：我们每个类独立地预测二进制掩码，而不是在各个类之间竞争，并依赖于网络的RoI分类分支来预测类别。相反，FCN通常执行每像素多类别分类，它结合了分割和分类，并且基于我们的实验在例如细分方面效果不佳。\par
没有花里胡哨，Mask R-CNN超越了所有COCO以前最先进的单一模型结果实例分割任务\custcite{28}，包括重工程2016年比赛获胜者的参赛作品。作为副产品，我们的方法也擅长COCO对象检测任务。在消融实验中，我们评估多个基本实例化，它允许我们展示它鲁棒性和分析核心因素的影响。我们的模型在GPU上每帧可以运行大约200ms，COCO的训练只需要8 GPU机器一到两天的时间。我们相信快速的训练和测试速度还有框架的灵活性和准确性会有利于和简化实例细分的未来研究。\par
最后，我们通过COCO数据集中人体关键点上的姿态估计任务展示了我们框架的一般性。 通过将每个关键点视为一个热点二进制掩码，以最小修改Mask R-CNN即可应用于检测特定于实例的姿势。我们已经发布了代码以促进未来的研究。\par
